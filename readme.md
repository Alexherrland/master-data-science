# Máster en Ingeniería y Ciencia de Datos - Repositorio de Proyectos

Este repositorio contiene la colección de trabajos prácticos y proyectos desarrollados durante el Máster Universitario en Ingeniería y Ciencia de Datos. El contenido abarca desde los fundamentos de la estadística y la programación hasta la implementación de arquitecturas complejas de Big Data y modelos avanzados de Inteligencia Artificial.

---

## 1. Estructura del Repositorio

El repositorio se organiza por asignaturas, cada una con su propia documentación detallada y código fuente, se irá actualizando mediante las vaya cursando:

### Aprendizaje Automático I (AA1)
Enfoque en modelos de aprendizaje supervisado y no supervisado utilizando el ecosistema Scikit-Learn.
* **Actividad 1:** Clasificación de alojamientos (Airbnb Madrid). Naive Bayes, KNN y Árboles de Decisión. (Nota: 9)
* **Actividad 2:** Regresión para predicción de precios. Optimización de hiperparámetros y validación cruzada. (Nota: 9.5)
* **Actividad 3:** Segmentación de datos mediante Clustering (K-Means, Jerárquico, DBSCAN) y PCA. (Nota: 8.5)



### Infraestructuras Computacionales para Datos Masivos (ICPDM)
Implementación de soluciones sobre arquitecturas distribuidas y procesamiento en tiempo real.
* **TP 1:** Procesamiento batch con PySpark DataFrames y Spark SQL sobre entornos Hadoop/Hive. (Nota: 8.8)
* **TP 2:** Ingesta de datos de movilidad (EMT Madrid) con Kafka y procesamiento en flujo con Spark Structured Streaming.



### Minería de Textos
Procesamiento de Lenguaje Natural (NLP) y extracción de conocimiento a partir de fuentes no estructuradas.
* **PR 1:** Reconocimiento de Entidades Nombradas (NER) con spaCy y optimización mediante reglas heurísticas. (Nota: 10)
* **PR 2:** Agrupamiento de documentos (Clustering) sobre el corpus Newsgroup utilizando TF-IDF y LSA. (Nota: 10)

### Modelo Estadístico de Datos (MED)
Fundamentos matemáticos y estadísticos para la inferencia y el modelado de datos.
* **PR 1:** Regresión lineal, análisis de residuos, curvas ROC y validación de hipótesis en R. (Nota: 10)
* **PR 2:** Regresión logística, análisis discriminante (LDA/QDA) y estudio de variables de confusión. (Nota: 8.5)

### Programación en Entornos de Datos (PED)
Desarrollo de software eficiente y gestión de datos con Python.
* **Práctica Final:** Procesamiento vectorizado de series históricas de préstamos (2001-2024) utilizando Pandas.

---

## 2. Tecnologías y Herramientas Principales

| Categoría | Tecnologías |
| :--- | :--- |
| **Lenguajes** | Python, R, SQL |
| **Data Science** | Pandas, NumPy, Scikit-Learn, SciPy, Matplotlib, Seaborn |
| **NLP** | spaCy, NLTK |
| **Big Data** | PySpark, Apache Kafka, Apache Hive, Hadoop |
| **Entornos** | Jupyter Notebooks, Google Colab, Docker |

---

## 3. Resumen de Calificaciones

A continuación se presenta un resumen de los resultados obtenidos en las entregas clave:

| Asignatura | Entrega | Calificación |
| :--- | :--- | :--- |
| Aprendizaje Automático I | Actividad 1 | 9.0 |
| Aprendizaje Automático I | Actividad 2 | 9.5 |
| Aprendizaje Automático I | Actividad 3 | 8.5 |
| Minería de Textos | PR 1 | 10.0 |
| Minería de Textos | PR 2 | 10.0 |
| Modelo Estadístico de Datos | PR 1 | 10.0 |
| Modelo Estadístico de Datos | PR 2 | 8.5 |

---

## 4. Perfil Técnico Desarrollado

A lo largo de este programa se han consolidado capacidades de:
1. **Ingeniería de Datos:** Diseño de pipelines ETL y gestión de flujos en tiempo real.
2. **Modelado Predictivo:** Capacidad para seleccionar, entrenar y validar algoritmos de clasificación, regresión y clustering.
3. **Análisis Estadístico:** Rigor en la validación de supuestos y análisis crítico de resultados significativos.
4. **Optimización de Código:** Uso de técnicas de vectorización y procesamiento paralelo para grandes volúmenes de datos.